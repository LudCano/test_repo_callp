{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPLETE ANALYSIS OF LIDAR LA PAZ\n",
    "## CALLP\n",
    "\n",
    "Author: Ludving Cano Fernandez\n",
    "\n",
    "_Based on the code written by Maria Fernanda, 2018._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pre-processing\n",
    "### 1.1. Data files\n",
    "Data obtained by LIDAR are formatted in the following way:\n",
    "\n",
    " - File formated with YYYY_MM_DD\n",
    "   - Inside there are files with the format DD_MM_YY_HR_HHMM_ AA.ch1.txt (ex. 03_12_18_HR1407_90.ch1.txt)\n",
    "\n",
    "The first three columns are respectively: HOUR, MINUTE, SECOND. But when the data is adquired the hours and minutes are taken as decimal, so we have $8,000000$, which for memory usage we can reduce to only $8$ and also we can round SECONDS to three decimals.\n",
    "\n",
    "In the other hand, we have comma (,) as decimal symbol, Python uses dots (.) as standard decimal symbol, so we need to transform all data to use this symbol.\n",
    "\n",
    "Data uses a tabulator (/t) as separator by default, we will keep it as it's easy to read different separators.\n",
    "\n",
    "Finally, we want to concatenate all data files of a day to a new file so we can read all data at once when we will process it.\n",
    "\n",
    "### 1.2. Concatenating data\n",
    "\n",
    "#### 1.2.1. `concatenate.py`\n",
    "\n",
    "This basic code has two main and one optional tasks:\n",
    "\n",
    "1. Replace all commas with dots\n",
    "2. Concatenate all files from a day into a new file named `YYYY_MM_DD_rawdata_AA.txt`\n",
    "3. (OPTIONAL) Convert hours and minutes to integers, and round seconds to three decimals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Cuál carpeta usar?\n",
      "2018_12_03 ..... 0\n",
      "2018_04_30 ..... 1\n",
      "Se encontraron 8 archivos\n",
      "--- 29.797842741012573 seconds ---\n",
      "Size of result file:  1.43 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "orig_data_path = \"/home/ludving/PROJ/LFA/LIDAR_Code/\"\n",
    "ls = os.listdir(orig_data_path)\n",
    "\n",
    "r = re.compile(\"^\\d{4}_\\d{2}_\\d{2}\")\n",
    "ls = list(filter(r.match, ls))\n",
    "\n",
    "print(\"¿Cuál carpeta usar?\")\n",
    "for i, j in enumerate(ls):\n",
    "    print(j, \".....\", i)\n",
    "\n",
    "#selection = int(input(\"Ingrese número: \"))\n",
    "selection = 1\n",
    "selection = ls[selection]\n",
    "new_path = orig_data_path + selection + \"/\"\n",
    "new_ls = os.listdir(new_path)\n",
    "\n",
    "r = re.compile(\"\\d{2}_\\d{2}_\\d{2}_HR\\d{4}_\\d{2}.ch1.txt\")\n",
    "ls = list(filter(r.match, new_ls))\n",
    "\n",
    "qtn = len(ls)\n",
    "print(\"Se encontraron\", qtn, \"archivos\")\n",
    "\n",
    "new_file = \"\"\n",
    "for i in ls:\n",
    "    file_path = new_path + i\n",
    "    with open(file_path, \"r\") as file:\n",
    "        ff = file.read()\n",
    "        ff = ff.replace(\",\", \".\")\n",
    "    new_file = new_file + ff + \"\\n\"\n",
    "    \n",
    "raw_path = \"/home/ludving/PROJ/LFA/LIDAR_Code/raw_data/resultt.txt\"\n",
    "with open(raw_path, \"w+\") as file:\n",
    "    file.write(new_file)\n",
    "    \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "size = os.path.getsize(\"/home/ludving/PROJ/LFA/LIDAR_Code/raw_data/resultt.txt\")\n",
    "print(\"Size of result file: \",round(float(size)/10e8,2), \"GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other 2 versions of `concatenate.py`, each one has different approaches to handle the data and to write a new file, also we write a bash (`concat.sh`), which has some disavantages: it has to copied into the data folder and is only executable on Linux.\n",
    "\n",
    "Now, the description of the other 3 codes:\n",
    "\n",
    "#### 1.2.2. `concatenate2.py`\n",
    "This version uses the `pandas` library, which nowadays is widely used in data science, as it's supposed that this handles numerical data efficiently, this code implements objectives (2) and (3) too. Sadly it's the slowest, as it has to run line by line and do the calculations, then append the data to a list and finally convert this list of lists to a pandas DataFrame that can be written as a .txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Cuál carpeta usar?\n",
      "2018_12_03 ..... 0\n",
      "2018_04_30 ..... 1\n",
      "Se encontraron 8 archivos\n",
      "--- 156.19528150558472 seconds ---\n",
      "Size of result file:  1.36 GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "orig_data_path = \"/home/ludving/PROJ/LFA/LIDAR_Code/\"\n",
    "ls = os.listdir(orig_data_path)\n",
    "\n",
    "r = re.compile(\"^\\d{4}_\\d{2}_\\d{2}\")\n",
    "ls = list(filter(r.match, ls))\n",
    "\n",
    "print(\"¿Cuál carpeta usar?\")\n",
    "for i, j in enumerate(ls):\n",
    "    print(j, \".....\", i)\n",
    "\n",
    "#selection = int(input(\"Ingrese número: \"))\n",
    "selection = 1\n",
    "selection = ls[selection]\n",
    "new_path = orig_data_path + selection + \"/\"\n",
    "new_ls = os.listdir(new_path)\n",
    "\n",
    "r = re.compile(\"\\d{2}_\\d{2}_\\d{2}_HR\\d{4}_\\d{2}.ch1.txt\")\n",
    "ls = list(filter(r.match, new_ls))\n",
    "\n",
    "qtn = len(ls)\n",
    "print(\"Se encontraron\", qtn, \"archivos\")\n",
    "\n",
    "new_file = \"\"\n",
    "ff = []\n",
    "for i in ls:\n",
    "    file_path = new_path + i\n",
    "    file = open(file_path)\n",
    "    for line in file:\n",
    "        lst = []\n",
    "        line = line.replace(\",\", \".\")\n",
    "        \"\"\"\n",
    "        dat = np.array(line.split())\n",
    "        dat = dat.astype(float)\n",
    "        for i in range(2):\n",
    "            dat[i] = dat[i].astype(int)\n",
    "        \"\"\"\n",
    "        for j in line.split():\n",
    "            lst.append(float(j))\n",
    "        lst[0] = int(lst[0])\n",
    "        lst[1] = int(lst[1])\n",
    "        lst[2] = round(lst[2],3)\n",
    "        ff.append(lst)\n",
    "        del(lst)\n",
    "        \n",
    "df = pd.DataFrame(ff)\n",
    "del(ff)\n",
    "df.to_csv('filename.txt', sep='\\t', index=False, header = False)\n",
    "\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "size = os.path.getsize('filename.txt')\n",
    "print(\"Size of result file: \",round(float(size)/10e8,2), \"GB\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
